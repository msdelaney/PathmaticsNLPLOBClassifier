{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture ste or others and then just bring in the suite numbers\n",
    "#seems hard to get the after to not take in anything.\n",
    "#\\d{1,5} [\\w\\s]{1,20} (?:street|st|avenue|ave|road|rd|highway|hwy|square|sq|trail|trl|drive|dr|court|ct|park|parkway|pkwy|circle|cir|boulevard|blvd|lane|ln|way|spc|expressway|ste)(?:\\s|\\W)(?:\\d{1,4})?(?:\\s)?(?:(ne|nw|se|sw|n|s|e|w)\\W)?(?:(ste\\W|suite\\W|space\\W|box\\W|bldg\\W|#)(?:#\\W|#)?[A-Za-z0-9]{0,6})?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Matthew.DeLaney\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Matthew.DeLaney\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import math\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import re\n",
    "import qgrid\n",
    "from pivottablejs import pivot_ui\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "lem = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension qgrid/extension...\n",
      "      - Validating: ok\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py --sys-prefix qgrid\n",
    "!jupyter nbextension enable --py --sys-prefix widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "social = pd.read_csv(r\"C:\\Users\\matthew.delaney\\OneDrive - Omnicom Media Group\\Documents\\ATTRework\\socialcreative\\full.csv\",skiprows=1,encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "socialcopy =social.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(r\"C:\\Users\\matthew.delaney\\OneDrive - Omnicom Media Group\\Documents\\ATTRework\\socialcreative\\creativetextv2.csv\",skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(s):\n",
    "    tokens = re.split('\\W+',s)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized):\n",
    "    text = []\n",
    "    for word in tokenized:\n",
    "        if word not in stopword:\n",
    "            text.append(word)\n",
    "    return text\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tokenized):\n",
    "    text = []\n",
    "    for word in tokenized:\n",
    "        text.append(ps.stem(word))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizing(tokenized):\n",
    "    text = []\n",
    "    for word in tokenized:\n",
    "        text.append(lem.lemmatize(word))\n",
    "    return text    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removal(x):\n",
    "\n",
    "    #Punctionation\n",
    "    remove = string.punctuation\n",
    "    remove = remove.replace(\"#\", \"\").replace('$','').replace('%','') # don't remove octothorpe |\"$\"|\"%\"\n",
    "    pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "    punc = re.compile(pattern)\n",
    "    emoji = re.compile( \"[\"\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "    \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "    \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "    \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "    \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "    \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "    \"\\U000024C2-\\U0001F251\" \n",
    "    \"]+\")\n",
    "    \n",
    "    #websites\n",
    "    link = re.compile('(?i)((?:https?://|www\\d{0,3}[.])?[a-z0-9.\\-]+[.](?:(?:international)|(?:construction)|(?:contractors)|(?:enterprises)|(?:photography)|(?:immobilien)|(?:management)|(?:technology)|(?:directory)|(?:education)|(?:equipment)|(?:institute)|(?:marketing)|(?:solutions)|(?:builders)|(?:clothing)|(?:computer)|(?:democrat)|(?:diamonds)|(?:graphics)|(?:holdings)|(?:lighting)|(?:plumbing)|(?:training)|(?:ventures)|(?:academy)|(?:careers)|(?:company)|(?:domains)|(?:florist)|(?:gallery)|(?:guitars)|(?:holiday)|(?:kitchen)|(?:recipes)|(?:shiksha)|(?:singles)|(?:support)|(?:systems)|(?:agency)|(?:berlin)|(?:camera)|(?:center)|(?:coffee)|(?:estate)|(?:kaufen)|(?:luxury)|(?:monash)|(?:museum)|(?:photos)|(?:repair)|(?:social)|(?:tattoo)|(?:travel)|(?:viajes)|(?:voyage)|(?:build)|(?:cheap)|(?:codes)|(?:dance)|(?:email)|(?:glass)|(?:house)|(?:ninja)|(?:photo)|(?:shoes)|(?:solar)|(?:today)|(?:aero)|(?:arpa)|(?:asia)|(?:bike)|(?:buzz)|(?:camp)|(?:club)|(?:coop)|(?:farm)|(?:gift)|(?:guru)|(?:info)|(?:jobs)|(?:kiwi)|(?:land)|(?:limo)|(?:link)|(?:menu)|(?:mobi)|(?:moda)|(?:name)|(?:pics)|(?:pink)|(?:post)|(?:rich)|(?:ruhr)|(?:sexy)|(?:tips)|(?:wang)|(?:wien)|(?:zone)|(?:biz)|(?:cab)|(?:cat)|(?:ceo)|(?:com)|(?:edu)|(?:gov)|(?:int)|(?:mil)|(?:net)|(?:onl)|(?:org)|(?:pro)|(?:red)|(?:tel)|(?:uno)|(?:xxx)|(?:ac)|(?:ad)|(?:ae)|(?:af)|(?:ag)|(?:ai)|(?:al)|(?:am)|(?:an)|(?:ao)|(?:aq)|(?:ar)|(?:as)|(?:at)|(?:au)|(?:aw)|(?:ax)|(?:az)|(?:ba)|(?:bb)|(?:bd)|(?:be)|(?:bf)|(?:bg)|(?:bh)|(?:bi)|(?:bj)|(?:bm)|(?:bn)|(?:bo)|(?:br)|(?:bs)|(?:bt)|(?:bv)|(?:bw)|(?:by)|(?:bz)|(?:ca)|(?:cc)|(?:cd)|(?:cf)|(?:cg)|(?:ch)|(?:ci)|(?:ck)|(?:cl)|(?:cm)|(?:cn)|(?:co)|(?:cr)|(?:cu)|(?:cv)|(?:cw)|(?:cx)|(?:cy)|(?:cz)|(?:de)|(?:dj)|(?:dk)|(?:dm)|(?:do)|(?:dz)|(?:ec)|(?:ee)|(?:eg)|(?:er)|(?:es)|(?:et)|(?:eu)|(?:fi)|(?:fj)|(?:fk)|(?:fm)|(?:fo)|(?:fr)|(?:ga)|(?:gb)|(?:gd)|(?:ge)|(?:gf)|(?:gg)|(?:gh)|(?:gi)|(?:gl)|(?:gm)|(?:gn)|(?:gp)|(?:gq)|(?:gr)|(?:gs)|(?:gt)|(?:gu)|(?:gw)|(?:gy)|(?:hk)|(?:hm)|(?:hn)|(?:hr)|(?:ht)|(?:hu)|(?:id)|(?:ie)|(?:il)|(?:im)|(?:in)|(?:io)|(?:iq)|(?:ir)|(?:is)|(?:it)|(?:je)|(?:jm)|(?:jo)|(?:jp)|(?:ke)|(?:kg)|(?:kh)|(?:ki)|(?:km)|(?:kn)|(?:kp)|(?:kr)|(?:kw)|(?:ky)|(?:kz)|(?:la)|(?:lb)|(?:lc)|(?:li)|(?:lk)|(?:lr)|(?:ls)|(?:lt)|(?:lu)|(?:lv)|(?:ly)|(?:ma)|(?:mc)|(?:md)|(?:me)|(?:mg)|(?:mh)|(?:mk)|(?:ml)|(?:mm)|(?:mn)|(?:mo)|(?:mp)|(?:mq)|(?:mr)|(?:ms)|(?:mt)|(?:mu)|(?:mv)|(?:mw)|(?:mx)|(?:my)|(?:mz)|(?:na)|(?:nc)|(?:ne)|(?:nf)|(?:ng)|(?:ni)|(?:nl)|(?:no)|(?:np)|(?:nr)|(?:nu)|(?:nz)|(?:om)|(?:pa)|(?:pe)|(?:pf)|(?:pg)|(?:ph)|(?:pk)|(?:pl)|(?:pm)|(?:pn)|(?:pr)|(?:ps)|(?:pt)|(?:pw)|(?:py)|(?:qa)|(?:re)|(?:ro)|(?:rs)|(?:ru)|(?:rw)|(?:sa)|(?:sb)|(?:sc)|(?:sd)|(?:se)|(?:sg)|(?:sh)|(?:si)|(?:sj)|(?:sk)|(?:sl)|(?:sm)|(?:sn)|(?:so)|(?:sr)|(?:st)|(?:su)|(?:sv)|(?:sx)|(?:sy)|(?:sz)|(?:tc)|(?:td)|(?:tf)|(?:tg)|(?:th)|(?:tj)|(?:tk)|(?:tl)|(?:tm)|(?:tn)|(?:to)|(?:tp)|(?:tr)|(?:tt)|(?:tv)|(?:tw)|(?:tz)|(?:ua)|(?:ug)|(?:uk)|(?:us)|(?:uy)|(?:uz)|(?:va)|(?:vc)|(?:ve)|(?:vg)|(?:vi)|(?:vn)|(?:vu)|(?:wf)|(?:ws)|(?:ye)|(?:yt)|(?:za)|(?:zm)|(?:zw))(?:/[^\\s()<>]+[^\\s`!()\\[\\]{};:\\'\".,<>?\\xab\\xbb\\u201c\\u201d\\u2018\\u2019])?)', re.IGNORECASE)\n",
    "    websites = re.compile('^(?#Protocol)(?:(?:ht|f)tp(?:s?)\\:\\/\\/|~\\/|\\/)?(?#Username:Password)(?:\\w+:\\w+@)?(?#Subdomains)(?:(?:[-\\w]+\\.)+(?#TopLevel Domains)(?:com|org|net|gov|mil|biz|info|mobi|name|aero|jobs|museum|travel|[a-z]{2}))(?#Port)(?::[\\d]{1,5})?(?#Directories)(?:(?:(?:\\/(?:[-\\w~!$+|.,=]|%[a-f\\d]{2})+)+|\\/)+|\\?|#)?(?#Query)(?:(?:\\?(?:[-\\w~!$+|.,*:]|%[a-f\\d{2}])+=?(?:[-\\w~!$+|.,*:=]|%[a-f\\d]{2})*)(?:&(?:[-\\w~!$+|.,*:]|%[a-f\\d{2}])+=?(?:[-\\w~!$+|.,*:=]|%[a-f\\d]{2})*)*)*(?#Anchor)(?:#(?:[-\\w~!$+|.,*:=]|%[a-f\\d]{2})*)?$',re.IGNORECASE)\n",
    "    https = re.compile('http\\S+', re.IGNORECASE)\n",
    "\n",
    "    #date and time\n",
    "    date = re.compile('(?:(?<!\\:)(?<!\\:\\d)[0-3]?\\d(?:st|nd|rd|th)?\\s+(?:of\\s+)?(?:jan\\.?|january|feb\\.?|february|mar\\.?|march|apr\\.?|april|may|jun\\.?|june|jul\\.?|july|aug\\.?|august|sep\\.?|september|oct\\.?|october|nov\\.?|november|dec\\.?|december)|(?:jan\\.?|january|feb\\.?|february|mar\\.?|march|apr\\.?|april|may|jun\\.?|june|jul\\.?|july|aug\\.?|august|sep\\.?|september|oct\\.?|october|nov\\.?|november|dec\\.?|december)\\s+(?<!\\:)(?<!\\:\\d)[0-3]?\\d(?:st|nd|rd|th)?)(?:\\,)?\\s*(?:\\d{4})?|[0-3]?\\d[-\\./][0-3]?\\d[-\\./]\\d{2,4}', re.IGNORECASE)\n",
    "    time = re.compile('\\d{1,2}:\\d{2} ?(?:[ap]\\.?m\\.?)?(?: [ECMP]T)?|\\d[ap]\\.?m\\.?(?: [ECMP]T)?', re.IGNORECASE)\n",
    "    dateMDY = re.compile('(1[0-2]|[1-9])\\/(3[01]|[12][0-9]|[1-9])\\/(\\d{2,4})')\n",
    "    dateMD = re.compile('(1[0-2]|[1-9])\\/(3[01]|[12][0-9]|[1-9])')\n",
    "    \n",
    "    #phones\n",
    "    phone = re.compile('''((?:(?<![\\d-])(?:\\+?\\d{1,3}[-.\\s*]?)?(?:\\(?\\d{3}\\)?[-.\\s*]?)?\\d{3}[-.\\s*]?\\d{4}(?![\\d-]))|(?:(?<![\\d-])(?:(?:\\(\\+?\\d{2}\\))|(?:\\+?\\d{2}))\\s*\\d{2}\\s*\\d{3}\\s*\\d{4}(?![\\d-])))''')\n",
    "    phones_with_exts = re.compile('((?:(?:\\+?1\\s*(?:[.-]\\s*)?)?(?:\\(\\s*(?:[2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|(?:[2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?(?:[2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?(?:[0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(?:\\d+)?))', re.IGNORECASE)\n",
    "    \n",
    "    #curr = r\"(?:[\\£\\$\\€]{1}[,\\d]+.?\\d*)\"\n",
    "\n",
    "\n",
    "    #address = re.compile('\\d{1,5} [\\w\\s]{1,20}(?:street|st|avenue|ave|road|rd|highway|hwy|square|sq|trail|trl|drive|dr|court|ct|park|parkway|pkwy|circle|cir|boulevard|blvd|lane|ln)\\W?(?=\\s|$)', re.IGNORECASE)\n",
    "    address = re.compile('\\d{1,5} [\\w\\s]{1,20} (?:street|st|avenue|ave|road|rd|highway|hwy|square|sq|trail|trl|drive|dr|court|ct|park|parkway|pkwy|circle|cir|boulevard|blvd|lane|ln|way|spc|expressway|pike|fwy|ctr|pl|route)(?:\\s|\\W)(?:\\d{1,4})?(?:\\s)?(?:(ne|nw|se|sw|n|s|e|w)\\W)?(?:(ste\\W|suite\\W|space\\W|box\\W|bldg\\W|unit\\W|#)(?:#\\W|#)?[A-Za-z0-9]{0,6})?',re.IGNORECASE)\n",
    "    suite   = re.compile('\\b(?:suite|ste)(?: # \\S{1,6}| \\S{1,6})')\n",
    "    #characters = r'[\\W\\_]'\n",
    "    \n",
    "    x = link.sub(' ',str(x))\n",
    "    x = date.sub(' ',str(x))\n",
    "    x = time.sub(' ',str(x))\n",
    "    x = websites.sub(' ',str(x))\n",
    "    x = https.sub(' ',str(x))\n",
    "    \n",
    "    x = address.sub(' ',str(x))\n",
    "    \n",
    "    x = dateMDY.sub(' ',str(x))\n",
    "    x = dateMD.sub(' ',str(x))\n",
    "    \n",
    "    x = phone.sub(' ',str(x))\n",
    "    x = phones_with_exts.sub(' ',str(x)) \n",
    "    \n",
    "    x = punc.sub(' ',str(x))\n",
    "    x = emoji.sub('',str(x))\n",
    "    #x = re.sub(r'[^\\w\\s]',' ',str(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['creative_text_clean'] = test['Creative Text'].apply(lambda x: removal(x))\n",
    "#test['creative_text_token'] = test['creative_text_clean'].apply(lambda x: tokenizer(x.lower()))\n",
    "#test['creative_text_no_stop'] = test['creative_text_token'].apply(lambda x: remove_stopwords(x))\n",
    "#test['creative_test_stemmed'] = test['creative_text_no_stop'].apply(lambda x: stemming(x))\n",
    "#test['creative_test_lemmatized'] = test['creative_text_no_stop'].apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test.sample(frac=.02, random_state=82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_excel(r\"C:\\Users\\matthew.delaney\\OneDrive - Omnicom Media Group\\Documents\\ATTRework\\socialcreative\\sample.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidftokenizer(s):\n",
    "    text = []\n",
    "    tokens = re.split('\\W+',s)\n",
    "    for word in tokens:\n",
    "        if word not in stopword:\n",
    "            text.append(lem.lemmatize(word))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = pd.read_excel(r\"C:\\Users\\matthew.delaney\\OneDrive - Omnicom Media Group\\Documents\\ATTRework\\socialcreative\\sampleMD.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled['creative_text_clean'] = labeled['Creative Text'].apply(lambda x: removal(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Advertiser',\n",
       " 'Brand Root',\n",
       " 'Brand (Major)',\n",
       " 'Brand (Minor)',\n",
       " 'Brand (Leaf)',\n",
       " 'Link to Creative',\n",
       " 'Creative Text',\n",
       " 'creative_text_clean']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.merge(labeled,socialcopy,how=\"left\",on=['Creative Text','Advertiser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcombined = combined.drop(['Brand (Minor)', 'Brand (Leaf)','Category','Region','Type','Landing Page',\n",
    " 'Link to Creative', 'Creative ID'],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcombined['LOB'] = dfcombined['LOB'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advertiser\n",
      "['Cox Communications, Inc.' 'Spectrum (Charter Communications)' 'Sprint'\n",
      " 'CenturyLink, Inc.' 'AT&T' 'Verizon' 'Comcast Corporation' 'DirecTV'\n",
      " 'Dish Network' 'CSC Holdings, LLC.' 'Altice N.V.'\n",
      " 'Time Warner Cable Enterprises LLC' 'Netflix, Inc.' 'Amazon.com'\n",
      " 'Bright House Networks' 'T-Mobile' 'CBS (cbs.com)' 'Sling TV (by Dish)'\n",
      " 'NBC Universal Television (nbc.com)' 'Hulu' 'Apple Inc.' 'Disney'\n",
      " 'Home Box Office, Inc. (HBO)' 'Boost Mobile (Boost Worldwide, Inc.)'\n",
      " 'Cricket Communications, Inc.' 'TracFone Wireless, Inc.' 'Lycamobile'\n",
      " 'MetroPCS Wireless, Inc.' 'Mint Mobile (Ultra Mobile (UVNV, Inc.))'\n",
      " 'Consumer Cellular' 'Virgin Mobile']\n",
      "31\n",
      "LOB\n",
      "['b2b' 'bbv' 'corp' 'other' 'ott' 'post' 'pre']\n",
      "7\n",
      "Site\n",
      "['facebook.com' 'twitter.com']\n",
      "2\n",
      "Device\n",
      "['Facebook' 'Twitter']\n",
      "2\n",
      "Brand Root\n",
      "['Business Solutions' 'All Business Services' 'Corporate' '<unbranded>'\n",
      " 'All B2B Non-Wireless Solutions' 'All Consumer Services' 'DirecTV Now'\n",
      " 'All Consumer In-Home Services' 'Optimum' 'Suddenlink Communication'\n",
      " 'All Consumer Broadband & Cable Services' 'Jobs' 'Prime Video'\n",
      " 'Developer Program' 'All Business Solutions'\n",
      " 'All Consumer Wireless Services' 'Altice' 'Fire TV' 'All Access'\n",
      " 'Netflix Corporate' 'Peacock TV' 'Netflix Originals (all shows & films)'\n",
      " 'Hulu Original Films' 'Apple TV' 'Disney Plus' 'Hulu Corporate'\n",
      " 'Hulu Original Shows' 'HBO Max' 'Business Promotions' 'Straight Talk']\n",
      "30\n",
      "Brand (Major)\n",
      "['Business Solutions' 'All Business Services' 'Corporate' '<unbranded>'\n",
      " 'All B2B Non-Wireless Solutions' 'Consumer Non-Wireless (Xfinity)'\n",
      " 'DirecTV Now' 'FiOS' 'All Consumer Services' 'Optimum'\n",
      " 'Suddenlink Communication' 'Consumer Non-Wireless'\n",
      " 'All Consumer Broadband & Cable Services' 'Jobs' 'Prime Video'\n",
      " 'Developer Program' 'Charter-Branded Business Solutions'\n",
      " 'All Business Solutions' 'NFL Promos' 'Altice' 'Hum' 'Fire TV'\n",
      " 'All Access' 'Netflix Corporate' 'Peacock TV' 'Stranger Things'\n",
      " 'Hulu Original Films' 'The Good Fight' 'Amazon Studios (all shows)'\n",
      " '13 Reasons Why' 'Apple TV+' 'The World According to Jeff Goldblum'\n",
      " 'Disney Plus' 'Star Trek: Discovery' 'Hulu Corporate' 'Trailer Park Boys'\n",
      " 'GLOW' 'Original Films' 'The Path' 'Jessica Jones' 'Solar Opposites'\n",
      " 'HBO Max' 'Consumer Wireless (Xfinity Mobile)' 'Business Promotions'\n",
      " 'All Data Plans' 'Straight Talk' 'Go90']\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "rt = ['Advertiser',\n",
    " 'LOB',\n",
    " 'Site',\n",
    " 'Device',\n",
    " 'Brand Root',\n",
    " 'Brand (Major)']\n",
    "\n",
    "for x  in rt:\n",
    "    print(x)\n",
    "    print(dfcombined[x].unique())\n",
    "    print(len(dfcombined[x].unique()))\n",
    "    #print(dfcombined[x].isnull().values.any())\n",
    "\n",
    "#dfcombined['Advertiser'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "dfcombined['LOB_vector'] = le.fit_transform(dfcombined['LOB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "labels = dfcombined['LOB_vector'].copy()\n",
    "features = dfcombined[['Advertiser','Brand (Major)','creative_text_clean']].copy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEAT_DESCP = 50000\n",
    "\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    [('advertiser_category', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['Advertiser']),\n",
    "     ('brand_major_cat', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['Brand (Major)']),\n",
    "     ('creativeclean_tfidf', TfidfVectorizer(max_features = MAX_FEAT_DESCP, stop_words = 'english', ngram_range=(1,3)), 'creative_text_clean')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(preprocess,RandomForestClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('advertiser_category',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories=None,\n",
       "                                                                drop=None,\n",
       "                                                                dtype='int',\n",
       "                                                                handle_unknown='ignore',\n",
       "                                                                n_values=None,\n",
       "                                                                sparse=True),\n",
       "                                                  ['Advertiser']),\n",
       "                                                 ('brand_major_cat',\n",
       "                                                  OneHotE...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904214559386973"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95238095 0.93142857 0.92938931 0.91395793 0.99042146 0.97509579\n",
      " 0.89443378 0.92692308 0.87861272 0.89017341]\n",
      "Accuracy: 0.93 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, features, labels, cv=10)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "erf_clf = ExtraTreesClassifier(n_estimators=10, max_depth=None, min_samples_split=1, random_state=0)\n",
    "\n",
    "\n",
    "scores = sklearn.cross_validation.cross_val_score(erf_clf, features, labels, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
